{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd326d83",
   "metadata": {},
   "source": [
    "# Modelo predictivo empleado en el Datathon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb96545",
   "metadata": {},
   "source": [
    "El siguiente modelo fue empleado en el Datathon Cajamar UniversityHack. Obtuvo el cuarto mejor resultado de la Universidad Complutense de Madrid entre más de 50 equipos. La justificación del modelo puede encontrarse en el pdf 'Presentacion', donde bajo argumentos científicos se justifica su uso. Dado que se trata de un modelo sencillo y sin algoritmos complejos, se presentarán posteriormente formas más sofisticadas de abordar el problema mediante modelos basados en XGBoost o redes neuronales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3a2747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comenzamos importando las librerías necesarias.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b40e050",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recuperamos el dataset original.\n",
    "df = pd.read_csv('UH_2023_TRAIN.txt', delimiter = \"|\")\n",
    "df22 = df[df['CAMPAÑA'] == 22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1a35df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos las distancias meteorológicas entre campañas y generamos las ponderaciones\n",
    "import pickle\n",
    "with open('distances_invertido.pickle', 'rb') as handle:\n",
    "    distancias = pickle.load(handle)\n",
    "pesos_temporales = np.array(list((reversed([1 / pow(math.e, i) for i in range(1, 7)]))))\n",
    "pesos_temporales_11 = np.array(list((reversed([1 / pow(math.e, i) for i in range(1, 6)]))))\n",
    "ponderaciones = distancias\n",
    "for key, value in distancias.items():\n",
    "    dict_vec = np.array([1/x for x in list(value.values())])\n",
    "    result = dict_vec * pesos_temporales\n",
    "    result = result / result.sum()\n",
    "    ponderaciones[key] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b2b1d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>ID_FINCA</th>\n",
       "      <th>200</th>\n",
       "      <th colspan=\"2\" halign=\"left\">439</th>\n",
       "      <th colspan=\"3\" halign=\"left\">447</th>\n",
       "      <th colspan=\"2\" halign=\"left\">523</th>\n",
       "      <th>528</th>\n",
       "      <th>702</th>\n",
       "      <th>...</th>\n",
       "      <th>99033</th>\n",
       "      <th>99108</th>\n",
       "      <th colspan=\"2\" halign=\"left\">99146</th>\n",
       "      <th>99282</th>\n",
       "      <th colspan=\"2\" halign=\"left\">99377</th>\n",
       "      <th>99693</th>\n",
       "      <th colspan=\"2\" halign=\"left\">99793</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>VARIEDAD</th>\n",
       "      <th>59</th>\n",
       "      <th>9</th>\n",
       "      <th>52</th>\n",
       "      <th colspan=\"2\" halign=\"left\">17</th>\n",
       "      <th>40</th>\n",
       "      <th>32</th>\n",
       "      <th>59</th>\n",
       "      <th>59</th>\n",
       "      <th>59</th>\n",
       "      <th>...</th>\n",
       "      <th>81</th>\n",
       "      <th>52</th>\n",
       "      <th colspan=\"2\" halign=\"left\">17</th>\n",
       "      <th>59</th>\n",
       "      <th colspan=\"2\" halign=\"left\">52</th>\n",
       "      <th>81</th>\n",
       "      <th>52</th>\n",
       "      <th>87</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>MODO</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>2</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>...</th>\n",
       "      <th>2</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>CAMPAÑA</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">PRODUCCION</th>\n",
       "      <th>14</th>\n",
       "      <td>1900.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2215.2</td>\n",
       "      <td>1824.700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2290.4</td>\n",
       "      <td>22780.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2284.2</td>\n",
       "      <td>4520.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6630.663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16856.590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>778.104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3208.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3242.106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11900.0</td>\n",
       "      <td>6480.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8000.800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2280.0</td>\n",
       "      <td>14480.844</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1636.200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6354.4</td>\n",
       "      <td>864.108</td>\n",
       "      <td>1660.176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7510.0</td>\n",
       "      <td>4080.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9230.000</td>\n",
       "      <td>560.0</td>\n",
       "      <td>990.0</td>\n",
       "      <td>15931.125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>829.008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1336.986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3732.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5300.0</td>\n",
       "      <td>6060.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5840.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20130.201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>607.212</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2836.074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5750.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3700.0</td>\n",
       "      <td>9070.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>17597.034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>392.688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1225.824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3380.0</td>\n",
       "      <td>7380.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1840.0</td>\n",
       "      <td>18405.387</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>545.400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2828.54</td>\n",
       "      <td>947.844</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6140.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>6710.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>26876.300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1901.402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2037.34</td>\n",
       "      <td>745.122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4490.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4730.0</td>\n",
       "      <td>8460.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2460.0</td>\n",
       "      <td>35418.700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 1946 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ID_FINCA               200       439               447                       \\\n",
       "VARIEDAD                  59        9       52        17                 40   \n",
       "MODO                       1         2       2         1         2        2   \n",
       "           CAMPAÑA                                                            \n",
       "PRODUCCION 14       1900.000       NaN  2215.2  1824.700       NaN      NaN   \n",
       "           15        778.104       NaN  3208.4       NaN  3242.106      NaN   \n",
       "           16       1636.200       NaN  6354.4   864.108  1660.176      NaN   \n",
       "           17        829.008       NaN     NaN       NaN  1336.986      NaN   \n",
       "           18        607.212       NaN     NaN       NaN       NaN      NaN   \n",
       "           19        392.688       NaN     NaN       NaN       NaN      NaN   \n",
       "           20        545.400       NaN     NaN       NaN       NaN  2828.54   \n",
       "           21            NaN  1901.402     NaN       NaN       NaN  2037.34   \n",
       "           22            NaN     0.000     NaN       NaN       NaN     0.00   \n",
       "\n",
       "ID_FINCA               523              528   702    ...   99033    99108  \\\n",
       "VARIEDAD                  32      59       59    59  ...      81       52   \n",
       "MODO                       2       1        1     2  ...       2        2   \n",
       "           CAMPAÑA                                   ...                    \n",
       "PRODUCCION 14            NaN  2290.4  22780.0   NaN  ...  2284.2   4520.0   \n",
       "           15            NaN     NaN      NaN   NaN  ...     NaN  11900.0   \n",
       "           16            NaN     NaN      NaN   NaN  ...     NaN   7510.0   \n",
       "           17       3732.000     NaN      NaN   NaN  ...     NaN   5300.0   \n",
       "           18       2836.074     NaN      NaN   NaN  ...     NaN   5750.0   \n",
       "           19       1225.824     NaN      NaN   NaN  ...     NaN   3300.0   \n",
       "           20        947.844     NaN      NaN   NaN  ...     NaN   6140.0   \n",
       "           21        745.122     NaN      NaN   NaN  ...     NaN   4490.0   \n",
       "           22          0.000     NaN      NaN   0.0  ...     NaN      0.0   \n",
       "\n",
       "ID_FINCA             99146             99282  99377              99693 99793  \\\n",
       "VARIEDAD                17                59     52                 81    52   \n",
       "MODO                     1       2         2      1       2          1     2   \n",
       "           CAMPAÑA                                                             \n",
       "PRODUCCION 14          NaN     NaN  6630.663    NaN     NaN  16856.590   NaN   \n",
       "           15       6480.0     NaN  8000.800    NaN  2280.0  14480.844   NaN   \n",
       "           16       4080.0     NaN  9230.000  560.0   990.0  15931.125   NaN   \n",
       "           17       6060.0     NaN  5840.000    NaN     NaN  20130.201   NaN   \n",
       "           18          NaN  3700.0  9070.000    NaN  2160.0  17597.034   NaN   \n",
       "           19          NaN  3380.0  7380.000    NaN  1840.0  18405.387   NaN   \n",
       "           20          NaN  3300.0  6710.000    NaN  2300.0  26876.300   NaN   \n",
       "           21          NaN  4730.0  8460.000    NaN  2460.0  35418.700   NaN   \n",
       "           22          NaN     0.0     0.000    NaN     0.0      0.000   0.0   \n",
       "\n",
       "ID_FINCA                 \n",
       "VARIEDAD             87  \n",
       "MODO                  2  \n",
       "           CAMPAÑA       \n",
       "PRODUCCION 14       NaN  \n",
       "           15       NaN  \n",
       "           16       NaN  \n",
       "           17       NaN  \n",
       "           18       NaN  \n",
       "           19       NaN  \n",
       "           20       NaN  \n",
       "           21       NaN  \n",
       "           22       0.0  \n",
       "\n",
       "[9 rows x 1946 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Genereamos un dataframe que muestre la evolución de la producción por finca, variedad y modo.\n",
    "df_group=df.groupby(['ID_FINCA', 'VARIEDAD', 'MODO', 'CAMPAÑA']).agg({'PRODUCCION':'sum'})\n",
    "df_group=df_group.unstack().transpose()\n",
    "df_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7591a563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6311.4863426966285"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Este código devuelve la esperanza de la producción en las campañas 20 y 21 para una finca que no\n",
    "# ha producido antes o ha producido algún año suelto. Al predecir habrá fincas cuya producción no\n",
    "# podamos estimar en base a producciones anteriores ni a variables meteorológicas. Queremos ver\n",
    "# si imputar por la media resulta adecuado.\n",
    "df_group_trans=df_group.transpose()\n",
    "df_group_trans\n",
    "lista = list(df_group_trans[('PRODUCCION', 20)][(df_group_trans.loc[:,('PRODUCCION',14)].isna()) & (df_group_trans.loc[:,('PRODUCCION',18)].isna()) & (df_group_trans.loc[:,('PRODUCCION',19)].isna()) & (df_group_trans.loc[:,('PRODUCCION',20)] > 0)])\n",
    "lista_21 = list(df_group_trans[('PRODUCCION', 21)][(df_group_trans.loc[:,('PRODUCCION',14)].isna()) & (df_group_trans.loc[:,('PRODUCCION',18)].isna()) & (df_group_trans.loc[:,('PRODUCCION',20)].isna()) & (df_group_trans.loc[:,('PRODUCCION',21)] > 0)])\n",
    "lista.extend(lista_21)\n",
    "vector = np.array(lista)\n",
    "vector.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a9c35b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"9\" halign=\"left\">PRODUCCION</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>CAMPAÑA</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_FINCA</th>\n",
       "      <th>VARIEDAD</th>\n",
       "      <th>MODO</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <th>40</th>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2828.540</td>\n",
       "      <td>2037.340</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3014</th>\n",
       "      <th>17</th>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>820.0</td>\n",
       "      <td>830.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.000</td>\n",
       "      <td>110.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6454</th>\n",
       "      <th>94</th>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6890.000</td>\n",
       "      <td>28560.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6950</th>\n",
       "      <th>23</th>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9010.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8623</th>\n",
       "      <th>26</th>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1853.500</td>\n",
       "      <td>4344.631</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9270</th>\n",
       "      <th>15</th>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16729.768</td>\n",
       "      <td>23860.724</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10925</th>\n",
       "      <th>9</th>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18550.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11220</th>\n",
       "      <th>87</th>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14120.000</td>\n",
       "      <td>20440.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11587</th>\n",
       "      <th>9</th>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7700.000</td>\n",
       "      <td>11640.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13333</th>\n",
       "      <th>94</th>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9800.000</td>\n",
       "      <td>8140.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13871</th>\n",
       "      <th>32</th>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9574.448</td>\n",
       "      <td>10038.960</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15071</th>\n",
       "      <th>81</th>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5280.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16921</th>\n",
       "      <th>40</th>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18070.000</td>\n",
       "      <td>18460.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17378</th>\n",
       "      <th>17</th>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>216.806</td>\n",
       "      <td>277.310</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17818</th>\n",
       "      <th>17</th>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.600</td>\n",
       "      <td>231.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18139</th>\n",
       "      <th>52</th>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5330.000</td>\n",
       "      <td>7450.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18318</th>\n",
       "      <th>81</th>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1820.000</td>\n",
       "      <td>8031.300</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19272</th>\n",
       "      <th>81</th>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2071.000</td>\n",
       "      <td>2981.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20082</th>\n",
       "      <th>15</th>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5658.887</td>\n",
       "      <td>5197.600</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20693</th>\n",
       "      <th>15</th>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31384.800</td>\n",
       "      <td>18177.030</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22639</th>\n",
       "      <th>40</th>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2456.160</td>\n",
       "      <td>1710.880</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24065</th>\n",
       "      <th>94</th>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12650.000</td>\n",
       "      <td>10200.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24195</th>\n",
       "      <th>87</th>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3260.000</td>\n",
       "      <td>7480.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25104</th>\n",
       "      <th>23</th>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15066.815</td>\n",
       "      <td>15687.576</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26831</th>\n",
       "      <th>40</th>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1031.745</td>\n",
       "      <td>743.145</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29262</th>\n",
       "      <th>23</th>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4864.188</td>\n",
       "      <td>11121.936</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31836</th>\n",
       "      <th>87</th>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7590.000</td>\n",
       "      <td>8654.500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32795</th>\n",
       "      <th>26</th>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7020.000</td>\n",
       "      <td>14930.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33453</th>\n",
       "      <th>32</th>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4888.830</td>\n",
       "      <td>12048.453</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34407</th>\n",
       "      <th>92</th>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>936.000</td>\n",
       "      <td>594.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       PRODUCCION                                       \\\n",
       "CAMPAÑA                        14     15     16  17  18  19         20   \n",
       "ID_FINCA VARIEDAD MODO                                                   \n",
       "447      40       2           NaN    NaN    NaN NaN NaN NaN   2828.540   \n",
       "3014     17       1           NaN  820.0  830.0 NaN NaN NaN     86.000   \n",
       "6454     94       2           NaN    NaN    NaN NaN NaN NaN   6890.000   \n",
       "6950     23       2           NaN    NaN    NaN NaN NaN NaN   9010.000   \n",
       "8623     26       2           NaN    NaN    NaN NaN NaN NaN   1853.500   \n",
       "9270     15       2           NaN    NaN    NaN NaN NaN NaN  16729.768   \n",
       "10925    9        2           NaN    NaN    NaN NaN NaN NaN  18550.000   \n",
       "11220    87       2           NaN    NaN    NaN NaN NaN NaN  14120.000   \n",
       "11587    9        2           NaN    NaN    NaN NaN NaN NaN   7700.000   \n",
       "13333    94       2           NaN    NaN    NaN NaN NaN NaN   9800.000   \n",
       "13871    32       2           NaN    NaN    NaN NaN NaN NaN   9574.448   \n",
       "15071    81       2           NaN    NaN    NaN NaN NaN NaN   5280.000   \n",
       "16921    40       2           NaN    NaN    NaN NaN NaN NaN  18070.000   \n",
       "17378    17       1           NaN    NaN    NaN NaN NaN NaN    216.806   \n",
       "17818    17       1           NaN    NaN    NaN NaN NaN NaN    180.600   \n",
       "18139    52       2           NaN    NaN    NaN NaN NaN NaN   5330.000   \n",
       "18318    81       2           NaN    NaN    NaN NaN NaN NaN   1820.000   \n",
       "19272    81       1           NaN    NaN    NaN NaN NaN NaN   2071.000   \n",
       "20082    15       2           NaN    NaN    NaN NaN NaN NaN   5658.887   \n",
       "20693    15       2           NaN    NaN    NaN NaN NaN NaN  31384.800   \n",
       "22639    40       2           NaN    NaN    NaN NaN NaN NaN   2456.160   \n",
       "24065    94       2           NaN    NaN    NaN NaN NaN NaN  12650.000   \n",
       "24195    87       2           NaN    NaN    NaN NaN NaN NaN   3260.000   \n",
       "25104    23       2           NaN    NaN    NaN NaN NaN NaN  15066.815   \n",
       "26831    40       2           NaN    NaN    NaN NaN NaN NaN   1031.745   \n",
       "29262    23       2           NaN    NaN    NaN NaN NaN NaN   4864.188   \n",
       "31836    87       2           NaN    NaN    NaN NaN NaN NaN   7590.000   \n",
       "32795    26       2           NaN    NaN    NaN NaN NaN NaN   7020.000   \n",
       "33453    32       2           NaN    NaN    NaN NaN NaN NaN   4888.830   \n",
       "34407    92       1           NaN    NaN    NaN NaN NaN NaN    936.000   \n",
       "\n",
       "                                        \n",
       "CAMPAÑA                        21   22  \n",
       "ID_FINCA VARIEDAD MODO                  \n",
       "447      40       2      2037.340  0.0  \n",
       "3014     17       1       110.000  0.0  \n",
       "6454     94       2     28560.000  0.0  \n",
       "6950     23       2           NaN  NaN  \n",
       "8623     26       2      4344.631  0.0  \n",
       "9270     15       2     23860.724  0.0  \n",
       "10925    9        2           NaN  NaN  \n",
       "11220    87       2     20440.000  0.0  \n",
       "11587    9        2     11640.000  0.0  \n",
       "13333    94       2      8140.000  0.0  \n",
       "13871    32       2     10038.960  0.0  \n",
       "15071    81       2           NaN  0.0  \n",
       "16921    40       2     18460.000  0.0  \n",
       "17378    17       1       277.310  0.0  \n",
       "17818    17       1       231.000  0.0  \n",
       "18139    52       2      7450.000  0.0  \n",
       "18318    81       2      8031.300  0.0  \n",
       "19272    81       1      2981.000  0.0  \n",
       "20082    15       2      5197.600  0.0  \n",
       "20693    15       2     18177.030  0.0  \n",
       "22639    40       2      1710.880  0.0  \n",
       "24065    94       2     10200.000  0.0  \n",
       "24195    87       2      7480.000  0.0  \n",
       "25104    23       2     15687.576  0.0  \n",
       "26831    40       2       743.145  0.0  \n",
       "29262    23       2     11121.936  0.0  \n",
       "31836    87       2      8654.500  0.0  \n",
       "32795    26       2     14930.000  0.0  \n",
       "33453    32       2     12048.453  0.0  \n",
       "34407    92       1       594.000  0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos a mostrar las campañas que comenzaron a producir cierta variedad en el año 2020. Existen \n",
    "# fincas con valores cercanos a cero y fincas con producciones superiores a la esperanza de\n",
    "# producción calculada en la celda anterior. Por ello imputar todas estas producciones por ese \n",
    "# valor no parece óptimo. Hemos comprobado que las fincas que inician con una producción más alta\n",
    "# cuentan con niveles de producción más elevados en las demás variedades. Así, una finca con una\n",
    "# producción media por variedad de 25.000 que inicia la producción en una nueva variedad suele\n",
    "# producir de inicio una cantidad muy superior a la producida por otra finca con una producción \n",
    "# media por variedad de 1.000 que igualmente comienza a producir una nueva variedad. Este hecho se\n",
    "# tendrá en cuenta en la función definida a continuación. Por lo general, la esperanza de producción \n",
    "# en la nueva variedad suele ser ligeramente inferior (alrededor del 75%) a la producción media de \n",
    "# la finca por variedad. La variabilidad aumenta a medida que el tamaño de la finca es mayor, es\n",
    "# decir, fincas con baja produccion no suelen producir cantidades grandes en nuevas variedades\n",
    "# pero fincas con alta producción sí que producen en ocasiones cantidades bajas en nuevas variedades.\n",
    "df_group_trans[(df_group_trans.loc[:,('PRODUCCION',14)].isna()) & (df_group_trans.loc[:,('PRODUCCION',18)].isna()) & (df_group_trans.loc[:,('PRODUCCION',19)].isna()) & (df_group_trans.loc[:,('PRODUCCION',20)] > 0)].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c5067b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta función da la predicción de producción para la campaña 22 de una finca, variedad y modo\n",
    "# concretos. Utiliza las ponderaciones de producción de campañas anteriores dadas en las variables\n",
    "# input campañas y pesos. Estas ponderaciones se calculan de manera externa en base a las similitudes\n",
    "# meteorológicas de las diferentes campañas teniendo en cuenta la estación a la que pertenece cada\n",
    "# finca. Se otorga además un mayor peso a las campañas más próximas en el tiempo a la campaña 22\n",
    "#para ajustar la predicción a la evolución tendencial de la producción.\n",
    "def prod22(finca, variedad, modo, campañas, pesos, df=df_group):\n",
    "    prod = [df.loc[('PRODUCCION',c), (finca, variedad, modo)] for c in campañas]\n",
    "    prod = [p for p in prod if p > 0]\n",
    "    if len(prod) == 0:\n",
    "        media_general = df.loc[:, (finca, variedad)].values.mean()\n",
    "        media_general_total = np.nanmean(df.loc[:, (finca)].values)\n",
    "        if media_general > 0:\n",
    "            produccion22 = media_general\n",
    "        elif media_general_total > 0:\n",
    "            produccion22 = 3/4*min(media_general_total, 15000) # Si la finca no producido esta \n",
    "            # variedad pero sí otras, imputamos el 75% de su producción media por variedad hasta\n",
    "            # una producción media máxima de 15.000. La justificación de estos valores se ha\n",
    "            # realizado en la celda anterior\n",
    "        else:\n",
    "            produccion22 = 6311 # Si la finca no ha producido nunca ninguna variedad imputamos la\n",
    "            # esperanza calculada anteriormente\n",
    "    else:\n",
    "        pesos_prod = [p * w for p, w in zip(prod, pesos)]\n",
    "        produccion22 = sum(pesos_prod) / sum(pesos[:len(prod)])\n",
    "    produccion22 = round(produccion22, 2)\n",
    "    return produccion22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "431afbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos la lista 'campañas', que recoge las campañas a tener en cuenta para las ponderaciones de\n",
    "# la función anterior. No se incluyen las campañas 14 y 15 por falta de datos meteorológicos.\n",
    "campañas = [16, 17, 18, 19, 20, 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07ee5713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos las predicciones en el dataframe df22 utilizando la función prod22, la lista 'campañas'\n",
    "# y el diccionario 'ponderaciones'.\n",
    "for fila in range(8526,9601):\n",
    "    df22.loc[fila, 'PRODUCCION'] = prod22(df.loc[fila, 'ID_FINCA'], df.loc[fila, 'VARIEDAD'], df.loc[fila, 'MODO'], campañas, ponderaciones[df.loc[fila, 'ID_ESTACION']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81ee786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos el formato a las condiciones requeridas y guardamos el dataframe resultante en un\n",
    "# archivo .txt\n",
    "df22.drop(['CAMPAÑA', 'ID_ZONA', 'ID_ESTACION', 'ALTITUD'], axis=1, inplace=True)\n",
    "df22['VARIEDAD']=df22['VARIEDAD'].astype(str)\n",
    "df22['VARIEDAD']=\"0\" + df22['VARIEDAD']\n",
    "df22=df22.sort_values(['ID_FINCA', 'VARIEDAD', 'MODO', 'TIPO', 'COLOR', 'SUPERFICIE'])\n",
    "df22.to_csv('output.txt', sep='|', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45f70266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1075 entries, 9240 to 8539\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   ID_FINCA    1075 non-null   int64  \n",
      " 1   VARIEDAD    1075 non-null   object \n",
      " 2   MODO        1075 non-null   int64  \n",
      " 3   TIPO        1075 non-null   int64  \n",
      " 4   COLOR       1075 non-null   int64  \n",
      " 5   SUPERFICIE  1075 non-null   float64\n",
      " 6   PRODUCCION  1075 non-null   float64\n",
      "dtypes: float64(2), int64(4), object(1)\n",
      "memory usage: 67.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df22.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "371e9bd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID_FINCA      0\n",
       "VARIEDAD      0\n",
       "MODO          0\n",
       "TIPO          0\n",
       "COLOR         0\n",
       "SUPERFICIE    0\n",
       "PRODUCCION    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comprobamos que no hay valores missing. Hemos asignado una predicción a cada fila.\n",
    "df22.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90683183",
   "metadata": {},
   "source": [
    "Los modelos 2, 3 y 4 presentan otras alternativas de predicción. Utilizan algoritmos de mayor complejidad, lo cual puede dar lugar a una mayor exactitud a cambio de perder interpretabilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155d9e62",
   "metadata": {},
   "source": [
    "# Otros modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3e2479",
   "metadata": {},
   "source": [
    "## Modelo 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080e1626",
   "metadata": {},
   "source": [
    "En el siguiente modelo XGBOOST usamos exclusivamente los datos contenidos en la base de train sin tener en cuenta la variable \n",
    "superficie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fafd8534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1235d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d749124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conjunto de datos de entrenamiento\n",
    "df1 = df.drop('SUPERFICIE', axis=1)\n",
    "df1421=df1[df1['CAMPAÑA'] != 22]\n",
    "#Conjunto de datos de test\n",
    "df22 = df1[df1['CAMPAÑA'] == 22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77749c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train y evaluación\n",
    "X = df1421.drop('PRODUCCION', axis=1).values\n",
    "y = df1421['PRODUCCION'].values.reshape(-1, 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1061bd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e14b97c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defino los hiperparámetros\n",
    "params = {'objective': 'reg:squarederror', \n",
    "          'max_depth': 6, \n",
    "          'learning_rate': 0.1, \n",
    "          'subsample': 0.5, \n",
    "          'colsample_bytree': 0.5,\n",
    "          'n_estimators': 100}\n",
    "\n",
    "# Entreno el modelo\n",
    "model = xgb.XGBRegressor(**params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realizamos predicciones en el conjunto de prueba\n",
    "y_pred_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21fa059b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE en train: 7385.70312\n",
      "MAE en train: 4347.64939\n",
      "R2 score: 0.6817699067121203\n"
     ]
    }
   ],
   "source": [
    "# Vemos como ha sido el entrenamiento\n",
    "y_pred_train=model.predict(X_train)\n",
    "rmse_train = mean_squared_error(y_train, y_pred_train, squared=False)\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "r2 = r2_score(y_train, y_pred_train)\n",
    "print(f'RMSE en train: {rmse_train:.5f}')\n",
    "print(f'MAE en train: {mae_train:.5f}')\n",
    "print(\"R2 score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca60df31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 8905.305603044813\n",
      "MAE: 5035.646735583654\n",
      "R2 score: 0.591792904102554\n"
     ]
    }
   ],
   "source": [
    "# En test\n",
    "rmse = mean_squared_error(y_test, y_pred_test, squared=False)\n",
    "print('RMSE:', rmse)\n",
    "mae=mean_absolute_error(y_test, y_pred_test)\n",
    "print('MAE:', mae)\n",
    "r2 = r2_score(y_test, y_pred_test)\n",
    "print(\"R2 score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8a59e8",
   "metadata": {},
   "source": [
    "## Modelo 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46c8431",
   "metadata": {},
   "source": [
    "En los siguientes modelos usamos exclusivamente los datos contenidos en la base de train, donde imputamos los 0's de la variable \n",
    "superficie como se indicó en el análisis exploratorio de TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cf399c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af9cf797",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un diccionario para ir guardando los resultados\n",
    "results_test_1 = {\n",
    "    'XGboost': {'RMSE': None, 'MAE': None, 'R2': None},\n",
    "    'GradientBoost': {'RMSE': None, 'MAE': None, 'R2': None},\n",
    "    'Red Neuronal': {'RMSE': None, 'MAE': None, 'R2': None},\n",
    "    'Bagging': {'RMSE': None, 'MAE': None, 'R2': None}\n",
    "}\n",
    "results_train_1 = {\n",
    "    'XGboost': {'RMSE': None, 'MAE': None, 'R2': None},\n",
    "    'GradientBoost': {'RMSE': None, 'MAE': None, 'R2': None},\n",
    "    'Red Neuronal': {'RMSE': None, 'MAE': None, 'R2': None},\n",
    "    'Bagging': {'RMSE': None, 'MAE': None, 'R2': None}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4cec1b",
   "metadata": {},
   "source": [
    "Entrenando con los datos de las CAMPAÑAS 14-21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7329368",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conjunto de datos de entrenamiento\n",
    "df1421=df[df['CAMPAÑA'] != 22]\n",
    "#Conjunto de datos de test\n",
    "df22 = df[df['CAMPAÑA'] == 22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30c955e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train y evaluación\n",
    "X = df1421.drop('PRODUCCION', axis=1).values\n",
    "y = df1421['PRODUCCION'].values.reshape(-1, 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c90ee6c",
   "metadata": {},
   "source": [
    "#### GRADIENT BOOSTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13cf09fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el modelo de Gradient Boosting\n",
    "gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.15, max_depth=6, random_state=42)\n",
    "\n",
    "# Ajustamos el modelo con los datos de entrenamiento\n",
    "gbr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_test=gbr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0be3b5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE en train: 3182.43477\n",
      "MAE en train: 2082.04738\n",
      "R2 score: 0.9409150904825445\n"
     ]
    }
   ],
   "source": [
    "# Vemos como ha sido el entrenamiento\n",
    "y_pred_train=gbr.predict(X_train)\n",
    "rmse_train = mean_squared_error(y_train, y_pred_train, squared=False)\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "r2 = r2_score(y_train, y_pred_train)\n",
    "print(f'RMSE en train: {rmse_train:.5f}')\n",
    "print(f'MAE en train: {mae_train:.5f}')\n",
    "print(\"R2 score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe7d1b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Las guardo en el diccionario\n",
    "results_train_1['GradientBoost']['RMSE'] = rmse_train\n",
    "results_train_1['GradientBoost']['MAE'] = mae_train\n",
    "results_train_1['GradientBoost']['R2'] = r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b01259c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 5621.3962151639125\n",
      "MAE: 3154.409804035481\n",
      "R2 score: 0.8373435504862835\n"
     ]
    }
   ],
   "source": [
    "# En test\n",
    "rmse = mean_squared_error(y_test, y_pred_test, squared=False)\n",
    "print('RMSE:', rmse)\n",
    "mae=mean_absolute_error(y_test, y_pred_test)\n",
    "print('MAE:', mae)\n",
    "r2 = r2_score(y_test, y_pred_test)\n",
    "print(\"R2 score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad53e814",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Las guardo en el diccionario\n",
    "results_test_1['GradientBoost']['RMSE'] = rmse\n",
    "results_test_1['GradientBoost']['MAE'] = mae\n",
    "results_test_1['GradientBoost']['R2'] = r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71fb3b3",
   "metadata": {},
   "source": [
    "#### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5548441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defino los hiperparámetros\n",
    "params = {'objective': 'reg:squarederror', \n",
    "          'max_depth': 6, \n",
    "          'learning_rate': 0.1, \n",
    "          'subsample': 0.5, \n",
    "          'colsample_bytree': 0.5,\n",
    "          'n_estimators': 100}\n",
    "\n",
    "# Entreno el modelo\n",
    "model = xgb.XGBRegressor(**params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realizamos predicciones en el conjunto de prueba\n",
    "y_pred_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91752b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE en train: 4664.18502\n",
      "MAE en train: 2805.48439\n",
      "R2 score: 0.87308612803866\n"
     ]
    }
   ],
   "source": [
    "# Vemos como ha sido el entrenamiento\n",
    "y_pred_train=model.predict(X_train)\n",
    "rmse_train = mean_squared_error(y_train, y_pred_train, squared=False)\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "r2 = r2_score(y_train, y_pred_train)\n",
    "print(f'RMSE en train: {rmse_train:.5f}')\n",
    "print(f'MAE en train: {mae_train:.5f}')\n",
    "print(\"R2 score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8cc87e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Las guardo en el diccionario\n",
    "results_train_1['XGboost']['RMSE'] = rmse_train\n",
    "results_train_1['XGboost']['MAE'] = mae_train\n",
    "results_train_1['XGboost']['R2'] = r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e550d393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 5809.922374595249\n",
      "MAE: 3399.3802489852674\n",
      "R2 score: 0.826250503732484\n"
     ]
    }
   ],
   "source": [
    "# En test\n",
    "rmse = mean_squared_error(y_test, y_pred_test, squared=False)\n",
    "print('RMSE:', rmse)\n",
    "mae=mean_absolute_error(y_test, y_pred_test)\n",
    "print('MAE:', mae)\n",
    "r2 = r2_score(y_test, y_pred_test)\n",
    "print(\"R2 score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28e557a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Las guardo en el diccionario\n",
    "results_test_1['XGboost']['RMSE'] = rmse\n",
    "results_test_1['XGboost']['MAE'] = mae\n",
    "results_test_1['XGboost']['R2'] = r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e220e49",
   "metadata": {},
   "source": [
    "#### BAGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c810fc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed892e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2285.091\n",
      "MAE: 1117.859\n",
      "R2:: 0.970\n"
     ]
    }
   ],
   "source": [
    "# Seleccionamos como modelo base un árbol de decisión\n",
    "base_model = DecisionTreeRegressor()\n",
    "\n",
    "# Creamos modelo de Bagging\n",
    "bagging_model = BaggingRegressor(base_estimator=base_model, n_estimators=100, random_state=30)\n",
    "\n",
    "# Entrenamos modelo con datos de entrenamiento\n",
    "bagging_model.fit(X_train, y_train)\n",
    "\n",
    "# Hacemos predicciones en conjunto de train\n",
    "y_pred_train = bagging_model.predict(X_train)\n",
    "rmse = mean_squared_error(y_train, y_pred_train, squared=False)\n",
    "mae = mean_absolute_error(y_train, y_pred_train)\n",
    "r2 = r2_score(y_train, y_pred_train)\n",
    "\n",
    "print(f\"RMSE: {rmse:.3f}\")\n",
    "print(f\"MAE: {mae:.3f}\")\n",
    "print(f\"R2:: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2b0581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Las guardo en el diccionario\n",
    "results_train_1['Bagging']['RMSE'] = rmse_train\n",
    "results_train_1['Bagging']['MAE'] = mae_train\n",
    "results_train_1['Bagging']['R2'] = r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c0abc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 5809.922\n",
      "MAE: 3399.380\n",
      "R2:: 0.826\n"
     ]
    }
   ],
   "source": [
    "# Hacemos predicciones en conjunto de test\n",
    "y_pred_train = bagging_model.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, y_pred_test, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred_test)\n",
    "r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"RMSE: {rmse:.3f}\")\n",
    "print(f\"MAE: {mae:.3f}\")\n",
    "print(f\"R2:: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a901ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Las guardo en el diccionario\n",
    "results_test_1['Bagging']['RMSE'] = rmse\n",
    "results_test_1['Bagging']['MAE'] = mae\n",
    "results_test_1['Bagging']['R2'] = r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae10d018",
   "metadata": {},
   "source": [
    "#### RED NEURONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4ad77bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 185167584.0000 - mean_absolute_error: 7948.3604 - root_mean_squared_error: 13607.6299 - val_loss: 210246000.0000 - val_mean_absolute_error: 9376.6621 - val_root_mean_squared_error: 14499.8623\n",
      "Epoch 2/10\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 176104288.0000 - mean_absolute_error: 7913.8901 - root_mean_squared_error: 13270.4287 - val_loss: 207987584.0000 - val_mean_absolute_error: 7592.4629 - val_root_mean_squared_error: 14421.7744\n",
      "Epoch 3/10\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 172923168.0000 - mean_absolute_error: 7949.9414 - root_mean_squared_error: 13150.0254 - val_loss: 193983952.0000 - val_mean_absolute_error: 8721.8955 - val_root_mean_squared_error: 13927.8125\n",
      "Epoch 4/10\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 171956160.0000 - mean_absolute_error: 8036.9160 - root_mean_squared_error: 13113.2051 - val_loss: 195662416.0000 - val_mean_absolute_error: 7964.4932 - val_root_mean_squared_error: 13987.9385\n",
      "Epoch 5/10\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 170409232.0000 - mean_absolute_error: 7953.6216 - root_mean_squared_error: 13054.0889 - val_loss: 193063376.0000 - val_mean_absolute_error: 8728.7480 - val_root_mean_squared_error: 13894.7246\n",
      "Epoch 6/10\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 170463984.0000 - mean_absolute_error: 7975.7197 - root_mean_squared_error: 13056.1855 - val_loss: 193930000.0000 - val_mean_absolute_error: 8882.4131 - val_root_mean_squared_error: 13925.8750\n",
      "Epoch 7/10\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 170289072.0000 - mean_absolute_error: 7966.9146 - root_mean_squared_error: 13049.4854 - val_loss: 192071920.0000 - val_mean_absolute_error: 8359.7188 - val_root_mean_squared_error: 13859.0010\n",
      "Epoch 8/10\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 170891616.0000 - mean_absolute_error: 7995.4004 - root_mean_squared_error: 13072.5518 - val_loss: 194467360.0000 - val_mean_absolute_error: 9155.7471 - val_root_mean_squared_error: 13945.1553\n",
      "Epoch 9/10\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 170036144.0000 - mean_absolute_error: 8003.9048 - root_mean_squared_error: 13039.7910 - val_loss: 195122096.0000 - val_mean_absolute_error: 7843.4009 - val_root_mean_squared_error: 13968.6113\n",
      "Epoch 10/10\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 168903120.0000 - mean_absolute_error: 7964.1890 - root_mean_squared_error: 12996.2734 - val_loss: 194527616.0000 - val_mean_absolute_error: 7843.4727 - val_root_mean_squared_error: 13947.3154\n",
      "214/214 [==============================] - 0s 1ms/step - loss: 169717040.0000 - mean_absolute_error: 7503.9004 - root_mean_squared_error: 13027.5488\n",
      "Pérdida en el conjunto de prueba: 169717040.0\n",
      "RMSE en el conjunto de prueba 13027.548828125\n",
      "MAE en el conjunto de prueba: 7503.900390625\n",
      "R2 en el conjunto de prueba: tf.Tensor(0.009891080799622864, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.metrics import MeanAbsoluteError, RootMeanSquaredError\n",
    "\n",
    "# Definir la arquitectura de la red neuronal\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Crear las instancias de las métricas MAE y R2\n",
    "mae = MeanAbsoluteError()\n",
    "rmse = RootMeanSquaredError()\n",
    "\n",
    "# Compilar el modelo con las métricas\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=[mae, rmse])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluar el modelo en el conjunto de entrenamiento\n",
    "loss, mae, rmse = model.evaluate(X_train, y_train)\n",
    "r2 = 1 - (rmse**2 / tf.math.reduce_variance(y_train))\n",
    "print(\"Pérdida en el conjunto de prueba:\", loss)\n",
    "print(\"RMSE en el conjunto de prueba\", rmse)\n",
    "print(\"MAE en el conjunto de prueba:\", mae)\n",
    "print(\"R2 en el conjunto de prueba:\", r2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7c5bea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Las guardo en el diccionario\n",
    "results_train_1['Red Neuronal']['RMSE'] = rmse\n",
    "results_train_1['Red Neuronal']['MAE'] = mae\n",
    "results_train_1['Red Neuronal']['R2'] = r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a4616509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 0s 1ms/step - loss: 194527616.0000 - mean_absolute_error: 7843.4727 - root_mean_squared_error: 13947.3154\n",
      "Pérdida en el conjunto de prueba: 194527616.0\n",
      "MAE en el conjunto de prueba: 7843.47265625\n",
      "R2 en el conjunto de prueba: tf.Tensor(0.999928208419033, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "loss, mae, mse = model.evaluate(X_test, y_test)\n",
    "r2 = 1 - (mse / tf.math.reduce_variance(y_test))\n",
    "print(\"Pérdida en el conjunto de prueba:\", loss)\n",
    "print(\"MAE en el conjunto de prueba:\", mae)\n",
    "print(\"R2 en el conjunto de prueba:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "827cca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Las guardo en el diccionario\n",
    "results_test_1['Red Neuronal']['RMSE'] = rmse\n",
    "results_test_1['Red Neuronal']['MAE'] = mae\n",
    "results_test_1['Red Neuronal']['R2'] = r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "69a6487d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nota:\n",
    "#Aunque GradientBoost aporta errores de test menores, parece que los resultados de XGboost \n",
    "#caen menos en el sobreajuste al haber menores diferencias entre los errores de entrenamiento y test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41945a16",
   "metadata": {},
   "source": [
    "## Modelo 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90179c0c",
   "metadata": {},
   "source": [
    "En este modelo incluiremos variables meteorológicas correspondientes a los meses de enero-junio (meses más importantes en el ciclo de la vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "344da8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3a41bdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('rhum_mes_16.pkl', 'rb') as file:\n",
    "    rhum_mes_16 = pickle.load(file)\n",
    "    \n",
    "with open('rhum_mes_17.pkl', 'rb') as file:\n",
    "    rhum_mes_17 = pickle.load(file)\n",
    "    \n",
    "with open('rhum_mes_18.pkl', 'rb') as file:\n",
    "    rhum_mes_18 = pickle.load(file)\n",
    "    \n",
    "with open('rhum_mes_19.pkl', 'rb') as file:\n",
    "    rhum_mes_19 = pickle.load(file)\n",
    "    \n",
    "with open('rhum_mes_20.pkl', 'rb') as file:\n",
    "    rhum_mes_20 = pickle.load(file)\n",
    "    \n",
    "with open('rhum_mes_21.pkl', 'rb') as file:\n",
    "    rhum_mes_21 = pickle.load(file)\n",
    "    \n",
    "with open('rhum_mes_22.pkl', 'rb') as file:\n",
    "    rhum_mes_22 = pickle.load(file)\n",
    "\n",
    "with open('windspeed_mes_16.pkl', 'rb') as file:\n",
    "    windspeed_mes_16 = pickle.load(file)\n",
    "    \n",
    "with open('windspeed_mes_17.pkl', 'rb') as file:\n",
    "    windspeed_mes_17 = pickle.load(file)\n",
    "    \n",
    "with open('windspeed_mes_18.pkl', 'rb') as file:\n",
    "    windspeed_mes_18 = pickle.load(file)\n",
    "    \n",
    "with open('windspeed_mes_19.pkl', 'rb') as file:\n",
    "    windspeed_mes_19 = pickle.load(file)\n",
    "    \n",
    "with open('windspeed_mes_20.pkl', 'rb') as file:\n",
    "    windspeed_mes_20 = pickle.load(file)\n",
    "    \n",
    "with open('windspeed_mes_21.pkl', 'rb') as file:\n",
    "    windspeed_mes_21 = pickle.load(file)\n",
    "    \n",
    "with open('windspeed_mes_22.pkl', 'rb') as file:\n",
    "    windspeed_mes_22 = pickle.load(file)\n",
    "\n",
    "with open('t_mes_15.pkl', 'rb') as file:\n",
    "    t_mes_15 = pickle.load(file)\n",
    "    \n",
    "with open('t_mes_16.pkl', 'rb') as file:\n",
    "    t_mes_16 = pickle.load(file)\n",
    "    \n",
    "with open('t_mes_17.pkl', 'rb') as file:\n",
    "    t_mes_17 = pickle.load(file)\n",
    "    \n",
    "with open('t_mes_18.pkl', 'rb') as file:\n",
    "    t_mes_18 = pickle.load(file)\n",
    "    \n",
    "with open('t_mes_19.pkl', 'rb') as file:\n",
    "    t_mes_19 = pickle.load(file)\n",
    "    \n",
    "with open('t_mes_20.pkl', 'rb') as file:\n",
    "    t_mes_20 = pickle.load(file)\n",
    "    \n",
    "with open('t_mes_21.pkl', 'rb') as file:\n",
    "    t_mes_21 = pickle.load(file)\n",
    "    \n",
    "with open('t_mes_22.pkl', 'rb') as file:\n",
    "    t_mes_22 = pickle.load(file)\n",
    "\n",
    "with open('precip_mes_16.pkl', 'rb') as file:\n",
    "    precip_mes_16 = pickle.load(file)\n",
    "\n",
    "with open('precip_mes_17.pkl', 'rb') as file:\n",
    "    precip_mes_17 = pickle.load(file)\n",
    "\n",
    "with open('precip_mes_18.pkl', 'rb') as file:\n",
    "    precip_mes_18 = pickle.load(file)\n",
    "\n",
    "with open('precip_mes_19.pkl', 'rb') as file:\n",
    "    precip_mes_19 = pickle.load(file)\n",
    "\n",
    "with open('precip_mes_20.pkl', 'rb') as file:\n",
    "    precip_mes_20 = pickle.load(file)\n",
    "\n",
    "with open('precip_mes_21.pkl', 'rb') as file:\n",
    "    precip_mes_21 = pickle.load(file)\n",
    "\n",
    "with open('precip_mes_22.pkl', 'rb') as file:\n",
    "    precip_mes_22 = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0b8f9894",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos una funcion para meter las variables meteorológicas de interés\n",
    "def metervariables(df):\n",
    "    meses=['enero', 'febrero', 'marzo', 'abril', 'mayo', 'junio']\n",
    "    for m in range(len(meses)):\n",
    "        precip_col = f\"precip_{meses[m]}\"\n",
    "        df[precip_col] = np.nan\n",
    "\n",
    "    # Rellenamos los valores de precip_mes en función de CAMPAÑA y ID_ESTACION\n",
    "    for c in range(16, 23):\n",
    "        for e in range(20):\n",
    "            for m in range(6):\n",
    "                precip_mes = globals()[f\"precip_mes_{c}\"][e][m]\n",
    "                mes_index = meses[m]\n",
    "                precip_col = f\"precip_{mes_index}\"\n",
    "                df.loc[(df['CAMPAÑA'] == c) & (df['ID_ESTACION'] == e), precip_col] = precip_mes\n",
    "    \n",
    "    for m in range(len(meses)):\n",
    "        windspeed_col = f\"windspeed_{meses[m]}\"\n",
    "        df[windspeed_col] = np.nan\n",
    "\n",
    "    # Rellenamos los valores de windspeed_mes en función de CAMPAÑA y ID_ESTACION\n",
    "    for c in range(16, 23):\n",
    "        for e in range(20):\n",
    "            for m in range(6):\n",
    "                windspeed_mes = globals()[f\"windspeed_mes_{c}\"][e][m]\n",
    "                mes_index = meses[m]\n",
    "                windspeed_col = f\"windspeed_{mes_index}\"\n",
    "                df.loc[(df['CAMPAÑA'] == c) & (df['ID_ESTACION'] == e), windspeed_col] = windspeed_mes\n",
    "\n",
    "    # Rellenamos los valores de temp_mes en función de CAMPAÑA y ID_ESTACION\n",
    "    for m in range(len(meses)):\n",
    "        temp_col = f\"t_mes_{meses[m]}\"\n",
    "        df[temp_col] = np.nan\n",
    "    for c in range(16, 23):\n",
    "        for e in range(20):\n",
    "            for m in range(6):\n",
    "                temp_mes = globals()[f\"t_mes_{c}\"][e][m]\n",
    "                mes_index = meses[m]\n",
    "                temp_col = f\"t_mes_{mes_index}\"\n",
    "                df.loc[(df['CAMPAÑA'] == c) & (df['ID_ESTACION'] == e), temp_col] = temp_mes\n",
    "    for m in range(len(meses)):\n",
    "        rhum_col = f\"rhum_mes_{meses[m]}\"\n",
    "        df[rhum_col] = np.nan\n",
    "    for c in range(16, 23):\n",
    "        for e in range(20):\n",
    "            for m in range(6):\n",
    "                rhum_mes = globals()[f\"rhum_mes_{c}\"][e][m]\n",
    "                mes_index = meses[m]\n",
    "                rhum_col = f\"rhum_mes_{mes_index}\"\n",
    "                df.loc[(df['CAMPAÑA'] == c) & (df['ID_ESTACION'] == e), rhum_col] = rhum_mes\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d8f9e425",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=metervariables(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1cbec765",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tenemos que eliminar los años de los que no disponemos datos meteorológicos\n",
    "campanas_eliminar = [14, 15, 22]\n",
    "df2 = df2[~df2['CAMPAÑA'].isin(campanas_eliminar)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f7c745a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un diccionario para ir guardando los resultados\n",
    "results_test_2 = {\n",
    "    'XGboost': {'RMSE': None, 'MAE': None, 'R2': None},\n",
    "    'GradientBoost': {'RMSE': None, 'MAE': None, 'R2': None},\n",
    "    'Red Neuronal': {'RMSE': None, 'MAE': None, 'R2': None},\n",
    "    'Bagging': {'RMSE': None, 'MAE': None, 'R2': None}\n",
    "}\n",
    "results_train_2 = {\n",
    "    'XGboost': {'RMSE': None, 'MAE': None, 'R2': None},\n",
    "    'GradientBoost': {'RMSE': None, 'MAE': None, 'R2': None},\n",
    "    'Red Neuronal': {'RMSE': None, 'MAE': None, 'R2': None},\n",
    "    'Bagging': {'RMSE': None, 'MAE': None, 'R2': None}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cba72b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train y evaluación\n",
    "X = df2.drop('PRODUCCION', axis=1).values\n",
    "y = df2['PRODUCCION'].values.reshape(-1, 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "414e0a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el modelo de Gradient Boosting\n",
    "gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.15, max_depth=6, random_state=42)\n",
    "\n",
    "# Ajustamos el modelo con los datos de entrenamiento\n",
    "gbr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_test=gbr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "78c6ad9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE en train: 2684.87778\n",
      "MAE en train: 1809.85876\n",
      "R2 score: 0.9587569927348677\n"
     ]
    }
   ],
   "source": [
    "# Vemos como ha sido el entrenamiento\n",
    "y_pred_train=gbr.predict(X_train)\n",
    "rmse_train = mean_squared_error(y_train, y_pred_train, squared=False)\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "r2 = r2_score(y_train, y_pred_train)\n",
    "print(f'RMSE en train: {rmse_train:.5f}')\n",
    "print(f'MAE en train: {mae_train:.5f}')\n",
    "print(\"R2 score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c5624f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Las guardo en el diccionario\n",
    "results_train_2['GradientBoost']['RMSE'] = rmse_train\n",
    "results_train_2['GradientBoost']['MAE'] = mae_train\n",
    "results_train_2['GradientBoost']['R2'] = r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e9ff034f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 5868.434744951996\n",
      "MAE: 3280.535787839327\n",
      "R2 score: 0.8126928635669151\n"
     ]
    }
   ],
   "source": [
    "# En test\n",
    "rmse = mean_squared_error(y_test, y_pred_test, squared=False)\n",
    "print('RMSE:', rmse)\n",
    "mae=mean_absolute_error(y_test, y_pred_test)\n",
    "print('MAE:', mae)\n",
    "r2 = r2_score(y_test, y_pred_test)\n",
    "print(\"R2 score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4da6a744",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Las guardo en el diccionario\n",
    "results_test_2['GradientBoost']['RMSE'] = rmse\n",
    "results_test_2['GradientBoost']['MAE'] = mae\n",
    "results_test_2['GradientBoost']['R2'] = r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe7b4d5",
   "metadata": {},
   "source": [
    "#### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dedbe9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defino los hiperparámetros\n",
    "params = {'objective': 'reg:squarederror', \n",
    "          'max_depth': 6, \n",
    "          'learning_rate': 0.1, \n",
    "          'subsample': 0.5, \n",
    "          'colsample_bytree': 0.5,\n",
    "          'n_estimators': 100}\n",
    "\n",
    "# Entreno el modelo\n",
    "model = xgb.XGBRegressor(**params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realizamos predicciones en el conjunto de prueba\n",
    "y_pred_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c3404280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE en train: 4303.45623\n",
      "MAE en train: 2678.16757\n",
      "R2 score: 0.8940414364389532\n"
     ]
    }
   ],
   "source": [
    "# Vemos como ha sido el entrenamiento\n",
    "y_pred_train=model.predict(X_train)\n",
    "rmse_train = mean_squared_error(y_train, y_pred_train, squared=False)\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "r2 = r2_score(y_train, y_pred_train)\n",
    "print(f'RMSE en train: {rmse_train:.5f}')\n",
    "print(f'MAE en train: {mae_train:.5f}')\n",
    "print(\"R2 score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "71d21319",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Las guardo en el diccionario\n",
    "results_train_2['XGboost']['RMSE'] = rmse_train\n",
    "results_train_2['XGboost']['MAE'] = mae_train\n",
    "results_train_2['XGboost']['R2'] = r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "50d55fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 6451.814761651902\n",
      "MAE: 3675.4190331559666\n",
      "R2 score: 0.7736015002642348\n"
     ]
    }
   ],
   "source": [
    "# En test\n",
    "rmse = mean_squared_error(y_test, y_pred_test, squared=False)\n",
    "print('RMSE:', rmse)\n",
    "mae=mean_absolute_error(y_test, y_pred_test)\n",
    "print('MAE:', mae)\n",
    "r2 = r2_score(y_test, y_pred_test)\n",
    "print(\"R2 score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f6d3e68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Las guardo en el diccionario\n",
    "results_test_2['XGboost']['RMSE'] = rmse\n",
    "results_test_2['XGboost']['MAE'] = mae\n",
    "results_test_2['XGboost']['R2'] = r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965eb117",
   "metadata": {},
   "source": [
    "#### BAGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "51f83f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2549.294\n",
      "MAE: 1245.888\n",
      "R2:: 0.963\n"
     ]
    }
   ],
   "source": [
    "# Seleccionamos como modelo base un árbol de decisión\n",
    "base_model = DecisionTreeRegressor()\n",
    "\n",
    "# Creamos modelo de Bagging\n",
    "bagging_model = BaggingRegressor(base_estimator=base_model, n_estimators=100, random_state=30)\n",
    "\n",
    "# Entrenamos modelo con datos de entrenamiento\n",
    "bagging_model.fit(X_train, y_train)\n",
    "\n",
    "# Hacemos predicciones en conjunto de train\n",
    "y_pred_train = bagging_model.predict(X_train)\n",
    "rmse = mean_squared_error(y_train, y_pred_train, squared=False)\n",
    "mae = mean_absolute_error(y_train, y_pred_train)\n",
    "r2 = r2_score(y_train, y_pred_train)\n",
    "\n",
    "print(f\"RMSE: {rmse:.3f}\")\n",
    "print(f\"MAE: {mae:.3f}\")\n",
    "print(f\"R2:: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b82ebf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Las guardo en el diccionario\n",
    "results_train_2['Bagging']['RMSE'] = rmse_train\n",
    "results_train_2['Bagging']['MAE'] = mae_train\n",
    "results_train_2['Bagging']['R2'] = r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0bef9629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 6451.815\n",
      "MAE: 3675.419\n",
      "R2:: 0.774\n"
     ]
    }
   ],
   "source": [
    "# Hacemos predicciones en conjunto de test\n",
    "y_pred_train = bagging_model.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, y_pred_test, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred_test)\n",
    "r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"RMSE: {rmse:.3f}\")\n",
    "print(f\"MAE: {mae:.3f}\")\n",
    "print(f\"R2:: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d54d900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Las guardo en el diccionario\n",
    "results_test_2['Bagging']['RMSE'] = rmse\n",
    "results_test_2['Bagging']['MAE'] = mae\n",
    "results_test_2['Bagging']['R2'] = r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67d936a",
   "metadata": {},
   "source": [
    "#### RED NEURONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1027b634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 192170208.0000 - mean_absolute_error: 8141.9038 - root_mean_squared_error: 13862.5469 - val_loss: 194459232.0000 - val_mean_absolute_error: 8095.1006 - val_root_mean_squared_error: 13944.8643\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 183338272.0000 - mean_absolute_error: 8033.3809 - root_mean_squared_error: 13540.2461 - val_loss: 200735904.0000 - val_mean_absolute_error: 7378.9683 - val_root_mean_squared_error: 14168.1299\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 180125056.0000 - mean_absolute_error: 8028.7554 - root_mean_squared_error: 13421.0674 - val_loss: 184792384.0000 - val_mean_absolute_error: 8845.5693 - val_root_mean_squared_error: 13593.8359\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 176279232.0000 - mean_absolute_error: 8126.8916 - root_mean_squared_error: 13277.0186 - val_loss: 182387696.0000 - val_mean_absolute_error: 8319.2080 - val_root_mean_squared_error: 13505.0986\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 175158384.0000 - mean_absolute_error: 8107.1665 - root_mean_squared_error: 13234.7412 - val_loss: 186928672.0000 - val_mean_absolute_error: 7799.2856 - val_root_mean_squared_error: 13672.1865\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 176064048.0000 - mean_absolute_error: 8133.1533 - root_mean_squared_error: 13268.9131 - val_loss: 183889632.0000 - val_mean_absolute_error: 8085.2163 - val_root_mean_squared_error: 13560.5908\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 174056608.0000 - mean_absolute_error: 8148.6431 - root_mean_squared_error: 13193.0518 - val_loss: 183814144.0000 - val_mean_absolute_error: 8026.3696 - val_root_mean_squared_error: 13557.8076\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 174995504.0000 - mean_absolute_error: 8151.6709 - root_mean_squared_error: 13228.5869 - val_loss: 181810384.0000 - val_mean_absolute_error: 8541.2686 - val_root_mean_squared_error: 13483.7080\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 173892736.0000 - mean_absolute_error: 8121.1138 - root_mean_squared_error: 13186.8398 - val_loss: 181533392.0000 - val_mean_absolute_error: 8363.7725 - val_root_mean_squared_error: 13473.4326\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 173504368.0000 - mean_absolute_error: 8098.5308 - root_mean_squared_error: 13172.1055 - val_loss: 181398480.0000 - val_mean_absolute_error: 8500.2520 - val_root_mean_squared_error: 13468.4258\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 172353008.0000 - mean_absolute_error: 8273.7891 - root_mean_squared_error: 13128.3281\n",
      "Pérdida en el conjunto de prueba: 172353008.0\n",
      "RMSE en el conjunto de prueba 13128.328125\n",
      "MAE en el conjunto de prueba: 8273.7890625\n",
      "R2 en el conjunto de prueba: tf.Tensor(0.013901887220463927, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "\n",
    "# Definir la arquitectura de la red neuronal\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "mae = MeanAbsoluteError()\n",
    "rmse = RootMeanSquaredError()\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=[mae, rmse])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluar el modelo en el conjunto de entrenamiento\n",
    "loss, mae, rmse = model.evaluate(X_train, y_train)\n",
    "r2 = 1 - (rmse**2 / tf.math.reduce_variance(y_train))\n",
    "print(\"Pérdida en el conjunto de prueba:\", loss)\n",
    "print(\"RMSE en el conjunto de prueba\", rmse)\n",
    "print(\"MAE en el conjunto de prueba:\", mae)\n",
    "print(\"R2 en el conjunto de prueba:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b00459f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Las guardo en el diccionario\n",
    "results_train_2['Red Neuronal']['RMSE'] = rmse\n",
    "results_train_2['Red Neuronal']['MAE'] = mae\n",
    "results_train_2['Red Neuronal']['R2'] = r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "78ed4a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 1ms/step - loss: 181398480.0000 - mean_absolute_error: 8500.2520 - root_mean_squared_error: 13468.4258\n",
      "Pérdida en el conjunto de prueba: 181398480.0\n",
      "RMSE en el conjunto de prueba 13468.42578125\n",
      "MAE en el conjunto de prueba: 8500.251953125\n",
      "R2 en el conjunto de prueba: tf.Tensor(0.013394710017420763, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "loss, mae, rmse = model.evaluate(X_test, y_test)\n",
    "r2 = 1 - (rmse**2 / tf.math.reduce_variance(y_test))\n",
    "print(\"Pérdida en el conjunto de prueba:\", loss)\n",
    "print(\"RMSE en el conjunto de prueba\", rmse)\n",
    "print(\"MAE en el conjunto de prueba:\", mae)\n",
    "print(\"R2 en el conjunto de prueba:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9a1ee10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Las guardo en el diccionario\n",
    "results_test_2['Red Neuronal']['RMSE'] = rmse\n",
    "results_test_2['Red Neuronal']['MAE'] = mae\n",
    "results_test_2['Red Neuronal']['R2'] = r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9b5c98fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'XGboost': {'RMSE': 5809.922374595249, 'MAE': 3399.3802489852674, 'R2': 0.826250503732484}, 'GradientBoost': {'RMSE': 5621.3962151639125, 'MAE': 3154.409804035481, 'R2': 0.8373435504862835}, 'Red Neuronal': {'RMSE': 13027.548828125, 'MAE': 7843.47265625, 'R2': <tf.Tensor: shape=(), dtype=float64, numpy=0.999928208419033>}, 'Bagging': {'RMSE': 5809.922374595249, 'MAE': 3399.3802489852674, 'R2': 0.826250503732484}}\n",
      "{'XGboost': {'RMSE': 6451.814761651902, 'MAE': 3675.4190331559666, 'R2': 0.7736015002642348}, 'GradientBoost': {'RMSE': 5868.434744951996, 'MAE': 3280.535787839327, 'R2': 0.8126928635669151}, 'Red Neuronal': {'RMSE': 13468.42578125, 'MAE': 8500.251953125, 'R2': <tf.Tensor: shape=(), dtype=float64, numpy=0.013394710017420763>}, 'Bagging': {'RMSE': 6451.814761651902, 'MAE': 3675.4190331559666, 'R2': 0.7736015002642348}}\n",
      "{'XGboost': {'RMSE': 4303.456228639298, 'MAE': 2678.167567581346, 'R2': 0.8940414364389532}, 'GradientBoost': {'RMSE': 2684.877783802826, 'MAE': 1809.8587634285097, 'R2': 0.9587569927348677}, 'Red Neuronal': {'RMSE': 13128.328125, 'MAE': 8273.7890625, 'R2': <tf.Tensor: shape=(), dtype=float64, numpy=0.013901887220463927>}, 'Bagging': {'RMSE': 4303.456228639298, 'MAE': 2678.167567581346, 'R2': 0.9628172907160456}}\n"
     ]
    }
   ],
   "source": [
    "print(results_test_1)\n",
    "print(results_test_2)\n",
    "print(results_train_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e2a1a4",
   "metadata": {},
   "source": [
    "Vemos que, incorporar las variables meteorológicas de precipitaciones, humedad, temperatura y fuerza del viento de los años de los que disponemos datos (16-21) y eliminar los años 14 y 15, aporta peores resultados que trabajar exclusivamente con el dataset de TRAIN imputando SUPERFICIE Y ALTITUD. LLegados a este punto, decidimos intentar codificar las variables CAMPAÑA o ID_ESTACION o ambas usando las variables meteorológicas.La codificación empleando los datos meteorológicos nos permitirá trabajar con datos de menor dimensión. Así, vamos a construir una serie de modelos empleando este enfoque."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
